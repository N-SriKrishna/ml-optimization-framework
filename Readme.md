# ML Model Optimization Framework

<div align="center">

![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![Tests](https://img.shields.io/badge/tests-27%2F27%20passing-brightgreen)
![License](https://img.shields.io/github/license/N-SriKrishna/ml-optimization-framework)
![Platform Support](https://img.shields.io/badge/platforms-7%20targets-orange)

**Intelligent framework for optimizing deep learning models with automatic constraint solving, multi-objective optimization, and hardware-aware deployment.**

[Quick Start](#-quick-start) â€¢ [Benchmarks](#-benchmarks) â€¢ [Features](#-features) â€¢ [Examples](#-examples)

</div>

---

## ğŸ¯ Why This Framework?

| Feature | Standard Tools | This Framework |
|---------|----------------|----------------|
| Optimization | Single technique | **100+ combinations tested** |
| Decision Making | Manual trial-error | **Automated constraint solving** |
| Deployment | Generic export | **Hardware-specific (7 platforms)** |
| Analysis | Model file only | **Reports + visualizations** |

**Real Results:** 3.67Ã— smaller models, 2.48Ã— faster inference, 96.6% accuracy retained
## ğŸ“Š Benchmarks

### Real-World Results: YOLOv8n

Optimized for **Snapdragon 8 Gen 2** (mobile deployment):

| Metric | Original | Optimized | Improvement |
|--------|----------|-----------|-------------|
| **Model Size** | 12.26 MB | 3.34 MB | **3.67Ã— smaller** â¬‡ï¸ |
| **Inference Latency** | 147 ms | 59 ms | **2.48Ã— faster** âš¡ |
| **Accuracy (mAP)** | 37.3% | 36.0% | **96.6% retained** âœ… |

**Optimization Applied:** Dynamic INT8 + Structured Pruning (35%)

---

## ğŸ¨ Visualizations

### Pareto Front Analysis (102 Combinations Tested)

Our framework automatically identifies **Pareto-optimal solutions** from **102 tested combinations** - configurations that offer the best trade-offs.

<table>
  <tr>
    <td width="50%">
      <img src="docs/images/pareto_accuracy_vs_latency.png" alt="Pareto Front: Accuracy vs Latency">
      <p align="center"><em>Accuracy vs Latency trade-offs</em></p>
    </td>
    <td width="50%">
      <img src="docs/images/pareto_accuracy_vs_size.png" alt="Pareto Front: Accuracy vs Size">
      <p align="center"><em>Accuracy vs Model Size</em></p>
    </td>
  </tr>
  <tr>
    <td width="50%">
      <img src="docs/images/combo_compression_speedup.png" alt="All Combinations">
      <p align="center"><em><strong>102 combinations tested</strong> (â­ = Pareto optimal)</em></p>
    </td>
    <td width="50%">
      <img src="docs/images/pareto_3d.png" alt="3D Pareto Surface">
      <p align="center"><em>3D Pareto visualization</em></p>
    </td>
  </tr>
</table>

### Detailed Analysis

<table>
  <tr>
    <td width="50%">
      <img src="docs/images/trade_off_heatmap.png" alt="Trade-off Heatmap">
      <p align="center"><em>Performance heatmap across 102 configurations</em></p>
    </td>
    <td width="50%">
      <img src="docs/images/pareto_radar.png" alt="Radar Comparison">
      <p align="center"><em>Multi-dimensional comparison (Top 20 variants)</em></p>
    </td>
  </tr>
</table>

### Key Results from 102 Combinations

| Metric | Value | Technique |
|--------|-------|-----------|
| **Best Compression** | 3.67Ã— | Dynamic INT8 + Magnitude 10% |
| **Best Speedup** | 3.04Ã— | Dynamic INT8 + Structured 65% |
| **Best Balanced** | Score 11.15 | Dynamic INT8 + Structured 65% |
| **Success Rate** | 100% (102/102) | All combinations worked |
| **Pareto Optimal** | 3 solutions | Automatically identified |

> ğŸ’¡ **All visualizations auto-generated** by running:
> ```
> python examples/real_world/02_optimize_yolov8.py
> ```


---

## ğŸš€ Quick Start

### Installation

```bash
git clone https://github.com/N-SriKrishna/ml-optimization-framework.git
cd ml-optimization-framework
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### In-Built Example

```python
git clone https://github.com/N-SriKrishna/ml-optimization-framework.git
cd ml-optimization-framework
pip install -q colorama onnx onnxruntime torch numpy pandas matplotlib pyyaml tqdm ultralytics
python examples/real_world/01_download_yolov8.py
python examples/real_world/02_optimize_yolov8.py
```

### Full Pipeline

```python
from src.analyzers.combination_explorer import CombinationExplorer
from src.converters.smart_deployment_exporter import SmartDeploymentExporter
from src.solvers.constraint_solver import HardwareConstraints

# Explore all combinations
explorer = CombinationExplorer('outputs')
results = explorer.explore_all_combinations('model.onnx', max_combinations=36)

# Get deployment recommendations
hardware = HardwareConstraints(device_name="Snapdragon 888", has_npu=True)
exporter = SmartDeploymentExporter()
exporter.create_deployment_package('model.onnx', hardware, 'outputs/deploy')
```

---

## ğŸ“Š Benchmarks

### YOLOv8n on Snapdragon 8 Gen 2

| Metric | Original | Optimized | Improvement |
|--------|----------|-----------|-------------|
| **Model Size** | 12.26 MB | 3.34 MB | **3.67Ã— smaller** â¬‡ï¸ |
| **Latency** | 147 ms | 59 ms | **2.48Ã— faster** âš¡ |
| **Memory** | 3.19M params | 2.06M params | **35% less** ğŸ’¾ |
| **Accuracy** | 37.3% mAP | 36.0% mAP | **96.6% retained** âœ… |
| **Power** | 2.4W | 0.98W | **59% less** ğŸ”‹ |

**Configuration:** Dynamic INT8 + Structured 35% Pruning

### Hardware Performance

| Platform | Runtime | Latency | Acceleration |
|----------|---------|---------|--------------|
| Snapdragon 888 | QNN | 59 ms | Hexagon NPU |
| Apple M2 | Core ML | 12 ms | Neural Engine |
| NVIDIA RTX 4090 | TensorRT | 3.2 ms | Tensor Cores |
| Intel Core i9 | OpenVINO | 45 ms | AVX512 |

---

## âœ¨ Features

### ğŸ”„ Universal Conversion
Convert PyTorch, TensorFlow, TFLite â†’ ONNX with auto-detection and validation

### ğŸ“ˆ Comprehensive Analysis
FLOPs, memory profiling, bottleneck identification, layer-wise breakdown

### âš¡ Multi-Technique Optimization
- **Quantization:** INT8, FP16, mixed-precision
- **Pruning:** Magnitude, structured, iterative
- **Graph Optimization:** Fusion, constant folding

### ğŸ§  Intelligent Constraint Solving

```python
from src.solvers.constraint_solver import ConstraintSolver, OptimizationConstraints

constraints = OptimizationConstraints(
    hardware=HardwareConstraints(device_name="Snapdragon 888", has_npu=True),
    performance=PerformanceConstraints(
        max_latency_ms=100,
        max_model_size_mb=20,
        min_accuracy=0.90
    ),
    optimization_goal='balanced'
)

solver = ConstraintSolver(constraints)
strategy = solver.solve(analysis)  # Auto-generates optimal strategy
```

### ğŸ”¬ Combination Explorer
Tests **102 combinations** (3 quantization Ã— 17 pruning Ã— 2 orderings) automatically with intelligent exploration

### ğŸ“Š Pareto Analysis
Multi-objective optimization with 7 visualization types (3D plots, radar charts, heatmaps)

### ğŸš€ Hardware-Aware Deployment
Auto-recommends optimal runtime for 7 platforms: Qualcomm, Apple, NVIDIA, Intel, MediaTek, ARM, Android

---

## ğŸ“ Examples

### Quick Optimization

```python
from src.optimizers.quantizer import quantize_dynamic_int8
from src.optimizers.pruner import prune_magnitude_global

quantize_dynamic_int8('model.onnx', 'model_int8.onnx')
prune_magnitude_global('model.onnx', 'model_pruned.onnx', sparsity=0.5)
```

### Complete Workflow

```bash
# Download and optimize YOLOv8
python examples/real_world/01_download_yolov8.py
python examples/real_world/02_optimize_yolov8.py

# Output: 5 variants, Pareto analysis, 7 visualizations, deployment guide
```

---

## ğŸ“ Project Structure

```
ml-optimization-framework/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ converters/          # Model conversion & deployment
â”‚   â”œâ”€â”€ analyzers/           # Analysis & combination exploration
â”‚   â”œâ”€â”€ optimizers/          # Quantization & pruning
â”‚   â”œâ”€â”€ solvers/             # Constraint solving
â”‚   â”œâ”€â”€ evaluators/          # Pareto analysis & visualization
â”‚   â””â”€â”€ utils/               # Utilities
â”œâ”€â”€ tests/                   # 27 tests, 100% coverage
â”œâ”€â”€ examples/                # Usage examples
â””â”€â”€ requirements.txt
```

---

## ğŸ§ª Testing

```bash
PYTHONPATH=. pytest tests/ -v
# 27 passed, 33 warnings in 17.31s
```

---

## ğŸ“Š Supported Models

**Object Detection:** YOLO (v5, v8, v11), SSD, EfficientDet, Faster R-CNN  
**Classification:** ResNet, EfficientNet, MobileNet, ViT  
**Segmentation:** U-Net, DeepLab, Mask R-CNN  
**Custom:** Any PyTorch/TensorFlow model exportable to ONNX

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/name`)
3. Add tests and ensure they pass
4. Submit Pull Request

---

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) file

---

## ğŸ™ Acknowledgments

ONNX Runtime, PyTorch, TensorFlow, Ultralytics, Qualcomm, Apple, NVIDIA

---

## ğŸ“§ Contact

- **Issues:** [Report bugs](https://github.com/N-SriKrishna/ml-optimization-framework/issues)
- **Discussions:** [Ask questions](https://github.com/N-SriKrishna/ml-optimization-framework/discussions)

---

## ğŸ”— Citation

```bibtex
@software{ml_optimization_framework,
  title={ML Model Optimization Framework},
  author={N Sri Krishna},
  year={2025},
  url={https://github.com/N-SriKrishna/ml-optimization-framework}
}
```

---

## ğŸš€ Roadmap

**v1.1:** Web GUI, transformer support, Docker  
**v1.2:** NAS, knowledge distillation, cloud deployment  
**v2.0:** GPTQ/AWQ, federated optimization, MLOps integration

---

<div align="center">

**â­ Star this repo if you find it useful! â­**

Made with â¤ï¸ for efficient AI deployment

[â¬† Back to Top](#ml-model-optimization-framework)

</div>
